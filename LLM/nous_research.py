# app.py
import streamlit as st
import requests


# --- ê¸°ë³¸ ì„¤ì • ---
st.set_page_config(page_title="Hermes-3 Chat", layout="centered")
st.title("ğŸ’¬ Hermes-3 LLaMA ëŒ€í™”í˜• ì±—ë´‡")

# --- ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ---
if "messages" not in st.session_state:
    st.session_state.messages = []

# --- ì˜µì…˜ ì¡°ì ˆ ìŠ¬ë¼ì´ë” ---
st.sidebar.header("ğŸ› ï¸ ëª¨ë¸ ì˜µì…˜")
temperature = st.sidebar.slider("Temperature", 0.0, 1.0, 0.7, 0.05)
top_p = st.sidebar.slider("Top-p", 0.0, 1.0, 0.9, 0.05)
max_tokens = st.sidebar.slider("Max Tokens", 50, 1024, 200, 10)

# --- ì‚¬ìš©ì ì…ë ¥ ë°›ê¸° ---
user_input = st.chat_input("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”...")

if user_input:
    # ëŒ€í™” ê¸°ë¡ì— ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
    st.session_state.messages.append({"role": "user", "content": user_input})

    # Hermes-3 API ìš”ì²­
    url = "https://inference-api.nousresearch.com/v1/chat/completions"
    headers = {
        "Content-Type": "application/json",
        "Authorization": "Bearer {api-key}"
    }
    data = {
        "model": "Hermes-3-Llama-3.1-70B",
        "messages": st.session_state.messages,
        "temperature": temperature,
        "top_p": top_p,
        "max_tokens": max_tokens
    }

    with st.spinner("ëª¨ë¸ì´ ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
        response = requests.post(url, headers=headers, json=data)

        if response.status_code == 200:
            reply = response.json()['choices'][0]['message']['content']
            st.session_state.messages.append({"role": "assistant", "content": reply})
        else:
            st.error("API ìš”ì²­ ì‹¤íŒ¨: " + response.text)

# --- ëŒ€í™” ì¶œë ¥ ---
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
